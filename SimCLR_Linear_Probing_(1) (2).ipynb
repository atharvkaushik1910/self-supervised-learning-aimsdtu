{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mc_oeupw2ZWS"
      },
      "source": [
        "Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nY8H76E52g1X"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgaj05sI83Da"
      },
      "source": [
        "Load class label mapping from Labels.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbmdepVG83fL"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Load class label mapping\n",
        "with open(\"ssl_dataset/Labels.json\", \"r\") as f:\n",
        "    label_map = json.load(f)\n",
        "\n",
        "# Sort class names by label index\n",
        "class_names = sorted(label_map, key=lambda k: label_map[k])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIGf1a1-2kNY"
      },
      "source": [
        "Load Labeled Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5p_B2to2m2A"
      },
      "outputs": [],
      "source": [
        "train_dirs = [\"ssl_dataset/train.X1\", \"ssl_dataset/train.X2\", \"ssl_dataset/train.X3\", \"ssl_dataset/train.X4\"]\n",
        "val_dir = \"ssl_dataset/val.X\"\n",
        "\n",
        "batch_size = 64\n",
        "img_size = (224, 224)\n",
        "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
        "\n",
        "# Load and normalize training datasets from all four folders\n",
        "all_ds = []\n",
        "for path in train_dirs:\n",
        "    ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        path,\n",
        "        label_mode='int',\n",
        "        image_size=img_size,\n",
        "        batch_size=batch_size,\n",
        "        class_names=class_names,\n",
        "        shuffle=True\n",
        "    )\n",
        "    ds = ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "    all_ds.append(ds)\n",
        "\n",
        "# Concatenate all datasets into one train_ds\n",
        "train_ds = all_ds[0]\n",
        "for ds in all_ds[1:]:\n",
        "    train_ds = train_ds.concatenate(ds)\n",
        "\n",
        "# Load and normalize validation dataset\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    val_dir,\n",
        "    label_mode='int',\n",
        "    image_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_names=class_names,\n",
        "    shuffle=False\n",
        ")\n",
        "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRI6F3qd3IW1"
      },
      "source": [
        "Load Frozen Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lmL0rp23JP8"
      },
      "outputs": [],
      "source": [
        "encoder = tf.keras.models.load_model('simclr_encoder.h5')\n",
        "encoder.trainable = False  # Freeze it!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdLEBEyN3LQb"
      },
      "source": [
        "Attach Linear Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LMIKRFn3PSp"
      },
      "outputs": [],
      "source": [
        "num_classes = 100  # For ImageNet-100\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8epJvon3VJL"
      },
      "source": [
        "Train Linear Classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpO4TWn43b25"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_ds, validation_data=val_ds, epochs=3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3bxqfr13f7W"
      },
      "source": [
        "Evaluate Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tL7qSgN3gkI"
      },
      "outputs": [],
      "source": [
        "# Get predictions and true labels\n",
        "y_true = np.concatenate([y.numpy() for x, y in val_ds], axis=0)\n",
        "y_pred_probs = model.predict(val_ds)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(y_true, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzo29G0F3k-d"
      },
      "source": [
        "Plot Accuracy & Loss Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8Tpgbml3nHW"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='Train Acc')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
        "plt.title('Accuracy Curve')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "plt.title('Loss Curve')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
