{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pFdZnuGxIUG"
      },
      "source": [
        "Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifL72kXnxF6t"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.keras import layers,models\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnyQv4xLxtUi"
      },
      "source": [
        "Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSCJqqFSyFai"
      },
      "outputs": [],
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.Rescaling(1./255),\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1),\n",
        "    layers.RandomContrast(0.1),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqLx4YxS0MZn"
      },
      "source": [
        "Load Training Datasets(No Label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOxy4s4V0Shv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "train_dirs = [f\"ssl_dataset/train.X{i}\" for i in range(1, 5)]\n",
        "\n",
        "def load_ssl_dataset():\n",
        "    all_datasets = []\n",
        "    for dir_path in train_dirs:\n",
        "        ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "            dir_path,\n",
        "            label_mode=None,\n",
        "            image_size=(224, 224),\n",
        "            batch_size=64\n",
        "        )\n",
        "        # Two views for SimCLR\n",
        "        ds = ds.map(lambda x: (data_augmentation(x), data_augmentation(x)))\n",
        "        all_datasets.append(ds)\n",
        "    return all_datasets\n",
        "\n",
        "ssl_datasets = load_ssl_dataset()\n",
        "\n",
        "\n",
        "train_ds = ssl_datasets.map(lambda x: (data_augmentation(x), data_augmentation(x)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MahaVIcn02dk"
      },
      "source": [
        "SimCLR Encoder + Projection Head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZagQgAxU06zJ"
      },
      "outputs": [],
      "source": [
        "def build_simclr_model():\n",
        "    base_model = tf.keras.applications.ResNet50(include_top=False, weights=None, pooling='avg', input_shape=(224, 224, 3))\n",
        "\n",
        "    inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "    features = base_model(inputs)\n",
        "\n",
        "    # Projection Head\n",
        "    x = layers.Dense(512, activation='relu')(features)\n",
        "    outputs = layers.Dense(128)(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mx7HcQLh1RsV"
      },
      "source": [
        "NT Xent Contrastive Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lygWWBjg1VL2"
      },
      "outputs": [],
      "source": [
        "def contrastive_loss(z_i, z_j, temperature=0.5):\n",
        "    # Normalize\n",
        "    z_i = tf.math.l2_normalize(z_i, axis=1)\n",
        "    z_j = tf.math.l2_normalize(z_j, axis=1)\n",
        "\n",
        "    batch_size = tf.shape(z_i)[0]\n",
        "    z = tf.concat([z_i, z_j], axis=0)\n",
        "\n",
        "    # Cosine similarity\n",
        "    sim_matrix = tf.matmul(z, z, transpose_b=True)\n",
        "    sim_matrix = sim_matrix / temperature\n",
        "\n",
        "    labels = tf.range(batch_size)\n",
        "    labels = tf.concat([labels, labels], axis=0)\n",
        "\n",
        "    # Create contrastive loss using cross-entropy\n",
        "    logits_mask = tf.linalg.diag(tf.ones_like(labels, dtype=tf.float32)) == 0\n",
        "    sim_matrix = tf.boolean_mask(sim_matrix, logits_mask)\n",
        "    sim_matrix = tf.reshape(sim_matrix, [2*batch_size, 2*batch_size - 1])\n",
        "\n",
        "    positives = tf.reduce_sum(z_i * z_j, axis=-1) / temperature\n",
        "    positives = tf.concat([positives, positives], axis=0)\n",
        "\n",
        "    loss = tf.keras.losses.sparse_categorical_crossentropy(labels, sim_matrix, from_logits=True)\n",
        "    return tf.reduce_mean(loss)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPZJhOP21Z7J"
      },
      "source": [
        "Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtzCsDNN1kal"
      },
      "outputs": [],
      "source": [
        "model = build_simclr_model()\n",
        "optimizer = tf.keras.optimizers.Adam(1e-3)\n",
        "\n",
        "@tf.function\n",
        "def train_step(x1, x2):\n",
        "    with tf.GradientTape() as tape:\n",
        "        z1 = model(x1, training=True)\n",
        "        z2 = model(x2, training=True)\n",
        "        loss = contrastive_loss(z1, z2)\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "    return loss\n",
        "\n",
        "# Training\n",
        "EPOCHS = 3\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    for ssl_ds in ssl_datasets:\n",
        "        for x1, x2 in tqdm(ssl_ds, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
        "            loss = train_step(x1, x2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TBBm48w1liH"
      },
      "source": [
        "Saving Encoder for Linear Probing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtCzIMld1rLH"
      },
      "outputs": [],
      "source": [
        "encoder = tf.keras.Model(inputs=model.input, outputs=model.layers[-3].output)\n",
        "encoder.save('simclr_encoder.h5')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
